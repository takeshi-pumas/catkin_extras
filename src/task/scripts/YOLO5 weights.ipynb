{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cebec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smach_utils2 import *\n",
    "img=rgbd.get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=rgbd.get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03307c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")  # or yolov5n - yolov5x6, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981a9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e45922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52746984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94223af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e347e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4fead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88958e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd326a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf001b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from yolov5.utils.dataloaders import LoadStreams, LoadImages\n",
    "from yolov5.utils.general import *\n",
    "#from yolov5.utils.general import check_img_size, check_requirements, check_imshow, colorstr, non_max_suppression, \\\n",
    "    #apply_classifier, scale_boxes, scale_segments, xyxy2xywh, strip_optimizer, set_logging, increment_path#, save_one_box\n",
    "from yolov5.utils.augmentations import letterbox\n",
    "from yolov5.utils.plots import colors, Annotator\n",
    "from yolov5.utils.torch_utils import * #select_device, load_classifier, time_sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_device('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a73979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from yolov5.utils.dataloaders import LoadStreams, LoadImages\n",
    "from yolov5.utils.general import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914c9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from yolov5.utils.dataloaders import LoadStreams, LoadImages\n",
    "from yolov5.utils.general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b7363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov5.utils.augmentations import letterbox\n",
    "from yolov5.utils.plots import colors, Annotator\n",
    "from yolov5.utils.torch_utils import * #select_device, load_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f68b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0efc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2023-7-23 Python-3.8.10 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 with Max-Q Design, 8109MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 369 layers, 21138024 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "device = select_device('')\n",
    "model=attempt_load('/home/roboworks/catkin_extras/src/yolov5_ros/scripts/yolov5/ycb.pt',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7c84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92238e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '001_chips_can',\n",
       " 1: '002_master_chef_can',\n",
       " 2: '003_cracker_box',\n",
       " 3: '004_sugar_box',\n",
       " 4: '005_tomato_soup_can',\n",
       " 5: '006_mustard_bottle',\n",
       " 6: '007_tuna_fish_can',\n",
       " 7: '008_pudding_box',\n",
       " 8: '009_gelatin_box',\n",
       " 9: '010_potted_meat_can',\n",
       " 10: '011_banana',\n",
       " 11: '012_strawberry',\n",
       " 12: '013_apple',\n",
       " 13: '014_lemon',\n",
       " 14: '015_peach',\n",
       " 15: '016_pear',\n",
       " 16: '017_orange',\n",
       " 17: '018_plum',\n",
       " 18: '019-a_pitcher_base',\n",
       " 19: '019-b_pitcher_base_v2',\n",
       " 20: '020_pitcher_lid',\n",
       " 21: '021_bleach_cleanser',\n",
       " 22: '022_windex_bottle',\n",
       " 23: '024_bowl',\n",
       " 24: '025_mug',\n",
       " 25: '026_sponge',\n",
       " 26: '029_plate',\n",
       " 27: '030_fork',\n",
       " 28: '031_spoon',\n",
       " 29: '033_spatula',\n",
       " 30: '040_large_marker',\n",
       " 31: '050_medium_clamp',\n",
       " 32: '051_large_clamp',\n",
       " 33: '052_extra_large_clamp',\n",
       " 34: '053-a_mini_soccer_ball',\n",
       " 35: '053-b_mini_soccer_ball_v2',\n",
       " 36: '054_softball',\n",
       " 37: '055_baseball',\n",
       " 38: '056_tennis_ball',\n",
       " 39: '057_racquetball',\n",
       " 40: '058_golf_ball',\n",
       " 41: '059_chain',\n",
       " 42: '061_foam_brick',\n",
       " 43: '062_dice',\n",
       " 44: '063-a_marbles',\n",
       " 45: '063-b_marbles',\n",
       " 46: '065-a_cups',\n",
       " 47: '065-b_cups',\n",
       " 48: '065-c_cups',\n",
       " 49: '065-d_cups',\n",
       " 50: '065-e_cups',\n",
       " 51: '065-f_cups',\n",
       " 52: '065-g_cups',\n",
       " 53: '065-h_cups',\n",
       " 54: '065-i_cups',\n",
       " 55: '065-j_cups',\n",
       " 56: '070-a_colored_wood_blocks',\n",
       " 57: '070-b_colored_wood_blocks',\n",
       " 58: '071_nine_hole_peg_test',\n",
       " 59: '072-a_toy_airplane',\n",
       " 60: '073-a_lego_duplo',\n",
       " 61: '073-b_lego_duplo',\n",
       " 62: '073-c_lego_duplo',\n",
       " 63: '073-d_lego_duplo',\n",
       " 64: '073-e_lego_duplo',\n",
       " 65: '073-f_lego_duplo',\n",
       " 66: '077_rubiks_cube'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f23426",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d02f0bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 369 layers, 21138024 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load model and weights to GPU via cuda if available\n",
    "model=attempt_load('/home/roboworks/catkin_extras/src/yolov5_ros/scripts/yolov5/ycb.pt',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be8e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 369 layers, 21138024 parameters, 0 gradients, 49.1 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac8a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(rgbd.get_image()).to(device)\n",
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f7b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f30682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 480, 640, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iimmgg=img.unsqueeze(0)\n",
    "iimmgg.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222bcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a54e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im=torch.moveaxis(iimmgg,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41835784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 480, 640])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c2077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34c77585",
   "metadata": {},
   "outputs": [],
   "source": [
    "res= model(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1b914f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18900, 72])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eede351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment= False\n",
    "pred = model(im, augment=augment, visualize=False)[0]\n",
    "conf_thres=0.5  # confidence threshold\n",
    "iou_thres=0.45  # NMS IOU threshold\n",
    "max_det=1000\n",
    "classes=0\n",
    "agnostic_nms=False\n",
    "D = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms,max_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "959c5a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([], device='cuda:0', size=(0, 6))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2737b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelc = load_classifier(name='resnet101', n=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6271b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5.utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebc603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21207b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6849b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424878b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784f274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a4245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b670f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe2239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2c117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f245d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261f36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d239c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b12a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd3a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d9fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11f3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1025c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05c954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724347c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf04c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_yaml('/known_locations.yaml')\n",
    "#read_yaml('/known_locations_sim.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b353c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aab69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=yaml_to_df('/known_locations.yaml')\n",
    "#df=yaml_to_df('/known_locations_sim.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xys=[]\n",
    "xys.append(df[df['child_id_frame']=='bedroom'][['x','y']].values.ravel())\n",
    "xys.append(df[df['child_id_frame']=='living_room'][['x','y']].values.ravel())\n",
    "xys.append(df[df['child_id_frame']=='dining_room'][['x','y']].values.ravel())\n",
    "xys.append(df[df['child_id_frame']=='kitchen'][['x','y']].values.ravel())\n",
    "room_names=['bedroom','living_room','dining_room','kitchen']\n",
    "xys, room_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "humanpose=detect_human_to_tf()  #make sure service is running\n",
    "humanpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.getTF('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a080d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "map_msg= rospy.wait_for_message('/prohibition_layer_map', OccupancyGrid)\n",
    "#map_msg= rospy.wait_for_message('/augmented_map', OccupancyGrid)\n",
    "inflated_map= np.asarray(map_msg.data)\n",
    "#cv2.imwrite('/home/roboworks/Pictures/inflatedmap.png',inflated_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_map=inflated_map.reshape((map_msg.info.width,map_msg.info.height))\n",
    "\n",
    "\n",
    "plt.imshow(img_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83857ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76147120",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=segmentation_server.call()\n",
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "\n",
    "if len(res.poses.data)==0: print( 'failed')\n",
    "else:\n",
    "    print('object found')\n",
    "    \n",
    "    poses=np.asarray(res.poses.data)\n",
    "    poses=poses.reshape((int(len(poses)/3) ,3     )      )  \n",
    "    num_objs=len(poses)\n",
    "    print (num_objs)\n",
    "    for i,pose in enumerate(poses):\n",
    "        #print (f'Occupancy map at point object {i}-> pixels ',origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m), img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)])\n",
    "        point_name=f'object_{i}'\n",
    "        tf_man.pub_static_tf(pos=pose, point_name=point_name, ref='head_rgbd_sensor_rgb_frame')## which object to choose   #TODO\n",
    "        rospy.sleep(0.3)\n",
    "        tf_man.change_ref_frame_tf(point_name=point_name, new_frame='map')\n",
    "        rospy.sleep(0.3)\n",
    "        pose,_= tf_man.getTF(point_name)\n",
    "        print (f'Occupancy map at point object {i}-> pixels ',origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m), img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)])\n",
    "        if img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]!=0:#### Yes axes seem to be \"flipped\" !=0:\n",
    "            print ('reject point, most likely part of arena, occupied inflated map')\n",
    "            tf_man.pub_static_tf(pos=[0,0,0], point_name=point_name, ref='head_rgbd_sensor_rgb_frame')\n",
    "            num_objs-=1\n",
    "        print (f\"object found at robot coords.{pose} \")\n",
    "\n",
    "print(num_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f31494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "humanpose=detect_human_to_tf()  #make sure service is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "if humanpose== False:\n",
    "    \n",
    "    print ('no human ')\n",
    "    \n",
    "else : \n",
    "    human_pose,_=tf_man.getTF('human')\n",
    "\n",
    "    pose=human_pose[:2]\n",
    "    \n",
    "    if img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]!=0:#### Yes axes seem to be \"flipped\" !=0:\n",
    "            print ('reject point, most likely part of the audience, outside of the arena map')\n",
    "            \n",
    "    dists=(pose-np.asarray(xys))\n",
    "    human_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'human in {human_room}')\n",
    "    \n",
    "    robot_pose=get_robot_px()\n",
    "    dists=(robot_pose-np.asarray(xys))\n",
    "    robot_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'Robot  in {robot_room}')\n",
    "    \n",
    "    if robot_room != human_room: print('maybe false positive... ignoring... ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5778f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a843a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_at (px,py, contoured):\n",
    "    contoured[px-5:px+5,py-5:py+5]=200\n",
    "    return contoured\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b67bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "iimg=draw_at(origin_map_img[1]+ round(pose[1]/pix_per_m), origin_map_img[0]+ round(pose[0]/pix_per_m) , img_map )\n",
    "#iimg=draw_at(origin_map_img[1], origin_map_img[0] , img_map )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(iimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose=human_pose\n",
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "\n",
    "print ('Occupancy map at point human-> pixels ',origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m), img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69a664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e553c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_pose,_=tf_man.getTF('human')\n",
    "human_pos=human_pose[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_pos=human_pose[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ca26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_pos=np.asarray([10.6,-2.33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0bd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists=(human_pos-np.asarray(xys))\n",
    "room_names[np.linalg.norm(dists, axis=1).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ee111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0debdc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xys.append(df[df['child_id_frame']=='bedroom'][['x','y']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc408bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=df[df['child_id_frame']=='bedroom'][['x','y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7feb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_map[300,285:315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imwrite('/home/roboworks/Pictures/imgmap.png', img_map)\n",
    "img_map_rooms=cv2.imread('/home/roboworks/Pictures/imgmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_map_rooms=cv2.imread('/home/roboworks/Pictures/imgmap_rooms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_map_rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iimg=draw_at(origin_map_img[1]+ round(pose[1]/pix_per_m), origin_map_img[0]+ round(pose[0]/pix_per_m) , img_map_rooms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(iimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_map_rooms=cv2.imread('/home/roboworks/catkin_extras/src/tmc_wrs_gazebo_world/maps/rc2023/map.pgm')\n",
    "\n",
    "img_map_rooms[origin_map_img[1]+ round(pose[1]/pix_per_m), origin_map_img[0]+ round(pose[0]/pix_per_m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#living_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "humanpose=detect_human_to_tf()  #make sure service is running\n",
    "if humanpose== False:\n",
    "    \n",
    "    print ('no human ')\n",
    "    \n",
    "else : \n",
    "    human_pose,_=tf_man.getTF('human')\n",
    "\n",
    "    pose=human_pose[:2]\n",
    "    \n",
    "    if img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]!=0:#### Yes axes seem to be \"flipped\" !=0:\n",
    "            print ('reject point, most likely part of the audience, outside of the arena map')\n",
    "            \n",
    "    dists=(pose-np.asarray(xys))\n",
    "    human_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'human in {human_room}')\n",
    "    \n",
    "    robot_pose=get_robot_px()\n",
    "    dists=(robot_pose-np.asarray(xys))\n",
    "    robot_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'Robot  in {robot_room}')\n",
    "    \n",
    "    if robot_room != human_room: print('maybe false positive... ignoring... ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afaf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_map_rooms=cv2.imread('/home/roboworks/Pictures/imgmap_rooms.png')\n",
    "img_map_rooms[origin_map_img[1]+ round(pose[1]/pix_per_m), origin_map_img[0]+ round(pose[0]/pix_per_m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "humanpose=detect_human_to_tf()  #make sure service is running\n",
    "if humanpose== False:\n",
    "    \n",
    "    print ('no human ')\n",
    "    \n",
    "else : \n",
    "    human_pose,_=tf_man.getTF('human')\n",
    "\n",
    "    pose=human_pose[:2]\n",
    "    \n",
    "    if img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]!=0:#### Yes axes seem to be \"flipped\" !=0:\n",
    "            print ('reject point, most likely part of the audience, outside of the arena map')\n",
    "            \n",
    "    dists=(pose-np.asarray(xys))\n",
    "    human_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'human in {human_room}')\n",
    "    \n",
    "    robot_pose=get_robot_px()\n",
    "    dists=(robot_pose-np.asarray(xys))\n",
    "    robot_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'Robot  in {robot_room}')\n",
    "    \n",
    "    if robot_room != human_room: print('maybe false positive... ignoring... ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ff4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_map_rooms=cv2.imread('/home/roboworks/Pictures/imgmap.png')\n",
    "img_map_rooms[origin_map_img[1]+ round(pose[1]/pix_per_m), origin_map_img[0]+ round(pose[0]/pix_per_m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376cd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "#cv2.imwrite('/home/roboworks/Pictures/imgmap.png', img_map)\n",
    "#img_map_rooms=cv2.imread('/home/roboworks/Pictures/imgmap.png')\n",
    "\n",
    "cropping = False\n",
    "\n",
    "x_start, y_start, x_end, y_end = 0, 0, 0, 0\n",
    "\n",
    "image = img_map_rooms\n",
    "oriImage = image.copy()\n",
    "ii = image.copy()\n",
    "room_no=0\n",
    "regions=[]\n",
    "global room_no , regions\n",
    "def mouse_crop(event, x, y, flags, param):\n",
    "    # grab references to the global variables\n",
    "    global x_start, y_start, x_end, y_end, cropping,room_no\n",
    "    \n",
    "    # if the left mouse button was DOWN, start RECORDING\n",
    "    # (x, y) coordinates and indicate that cropping is being\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        \n",
    "\n",
    "        x_start, y_start, x_end, y_end = x, y, x, y\n",
    "        cropping = True\n",
    "        \n",
    "\n",
    "    # Mouse is Moving\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if cropping :\n",
    "            x_end, y_end = x, y\n",
    "\n",
    "    # if the left mouse button was released\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # record the ending (x, y) coordinates\n",
    "        x_end, y_end = x, y\n",
    "        cropping = False # cropping is finished\n",
    "\n",
    "        refPoint = [(x_start, y_start), (x_end, y_end)]\n",
    "\n",
    "        if len(refPoint) == 2: #when two points were found\n",
    "            room_no+=1\n",
    "            print (room_no)\n",
    "            cv2.rectangle(ii, (x_start, y_start), (x_end, y_end), (255*np.random.rand(),255*np.random.rand(),255*np.random.rand()), -1)\n",
    "            regions.append(((x_start, y_start), (x_end, y_end)))\n",
    "            print (regions)\n",
    "            cv2.putText(ii, f'room{room_no}', (x_end,y_end),cv2.FONT_HERSHEY_SIMPLEX, 1 , (255, 0, 0),cv2.LINE_4)\n",
    "            cv2.imshow(\"rooms\", ii)\n",
    "\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", mouse_crop)\n",
    "\n",
    "while True:\n",
    "\n",
    "    i = image.copy()\n",
    "\n",
    "    if not cropping:\n",
    "        cv2.imshow(\"image\", image)\n",
    "\n",
    "    elif cropping:\n",
    "        cv2.rectangle(i, (x_start, y_start), (x_end, y_end), (255, 255,255), 6)\n",
    "        cv2.imshow(\"image\", i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    keystroke = cv2.waitKey(0)\n",
    "    if 32 <= keystroke and keystroke < 128:\n",
    "        key = chr(keystroke).lower()\n",
    "        print (key)\n",
    "        if key=='q':\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            break\n",
    "\n",
    "\n",
    "living_room_px_region=np.asarray(regions[0])\n",
    "kitchen_px_region=np.asarray(regions[1])\n",
    "bedroom_px_region=np.asarray(regions[2])\n",
    "dining_room_px_region=np.asarray(regions[3])\n",
    "    \n",
    "# close all open windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "living_room_px_region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133955b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=np.asarray(regions[0])\n",
    "living_room_px_region=np.asarray([(241, 222), (322, 328)])\n",
    "print(l , living_room_px_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "iimg=draw_at(px_pose[1],px_pose[0],img_map)\n",
    "plt.imshow (iimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray((origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19030ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose=get_robot_px()\n",
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "\n",
    "px_pose=np.asarray((origin_map_img[0]+pose[0],origin_map_img[1]+pose[1]))\n",
    "px_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91890f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "humanpose=detect_human_to_tf()  #make sure service is running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##REAL LAB\n",
    "#living_room_px_region=np.asarray([(422, 190), (494, 254)])\n",
    "#dining_room_px_region=np.asarray([(419, 144), (497, 196)])\n",
    "#kitchen_px_region=np.asarray([(385, 185), (425, 243)])\n",
    "#bedroom_px_region=np.asarray([(320, 173), (372, 238)])\n",
    "\n",
    "\n",
    "##RC SIM\n",
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "\n",
    "living_room_px_region=np.asarray([(241, 222), (322, 328)])\n",
    "kitchen_px_region=np.asarray([(331, 220), (414, 328)])\n",
    "\n",
    "bedroom_px_region=np.asarray([(331, 164), (412, 208)])\n",
    "dining_room_px_region=np.asarray([(239, 163), (320, 214)])\n",
    "\n",
    "\n",
    "def check_room_px(px_pose):\n",
    "    \n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            px_region=living_room_px_region\n",
    "            region='living_room'\n",
    "        if i==1:\n",
    "            px_region=kitchen_px_region\n",
    "            region='kitchen'\n",
    "        if i==2:\n",
    "            px_region=bedroom_px_region\n",
    "            region='bedroom'\n",
    "        if i==3:\n",
    "            px_region=dining_room_px_region\n",
    "            region='dining_room'\n",
    "        #print (region,px_region,px_pose)\n",
    "        if (px_pose[1]< px_region[1,1]) and (px_pose[1]> px_region[0,1]) and (px_pose[0]> px_region[0,0]) and (px_pose[0]< px_region[1,0]) : \n",
    "            print (f'in  {region}')\n",
    "            return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "humanpose=detect_human_to_tf()  #make sure service is running\n",
    "\n",
    "if humanpose== False:\n",
    "    \n",
    "    print ('no human ')\n",
    "    \n",
    "else : \n",
    "    human_pose,_=tf_man.getTF('human')\n",
    "\n",
    "    pose=human_pose[:2]\n",
    "    px_pose_human=np.asarray(([origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]))\n",
    "    if img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]!=0:#### Yes axes seem to be \"flipped\" !=0:\n",
    "            print ('reject point, most likely part of the audience, outside of the arena map')\n",
    "    \n",
    "    pose=get_robot_px()\n",
    "    px_pose_robot=np.asarray((origin_map_img[0]+pose[0],origin_map_img[1]+pose[1]))\n",
    "    origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "    room_robot,room_human=check_room_px(px_pose_robot),check_room_px(np.flip(px_pose_human))\n",
    "\n",
    "    print ('px robot',px_pose_robot,px_pose_human)\n",
    "    print('room_robot,room_human',room_robot,room_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39421853",
   "metadata": {},
   "outputs": [],
   "source": [
    "##REAL LAB\n",
    "living_room_px_region=np.asarray([(422, 190), (494, 254)])\n",
    "dining_room_px_region=np.asarray([(419, 144), (497, 196)])\n",
    "kitchen_px_region=np.asarray([(385, 185), (425, 243)])\n",
    "bedroom_px_region=np.asarray([(320, 173), (372, 238)])\n",
    "\n",
    "\n",
    "##RC SIM\n",
    "living_room_px_region=np.asarray([(241, 222), (322, 328)])\n",
    "kitchen_px_region=np.asarray([(331, 220), (414, 328)])\n",
    "\n",
    "bedroom_px_region=np.asarray([(331, 164), (412, 208)])\n",
    "dining_room_px_region=np.asarray([(239, 163), (320, 214)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7546cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]\n",
    "humanpose=detect_human_to_tf()  #make sure service is running\n",
    "humanpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_pose,_=tf_man.getTF('human')\n",
    "\n",
    "pose=human_pose[:2]\n",
    "if img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]!=0:#### Yes axes seem to be \"flipped\" !=0:\n",
    "        print ('reject point, most likely part of the audience, outside of the arena map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c80301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if humanpose== False:\n",
    "    \n",
    "    print ('no human ')\n",
    "    \n",
    "else : \n",
    "    human_pose,_=tf_man.getTF('human')\n",
    "\n",
    "    pose=human_pose[:2]\n",
    "    \n",
    "    if img_map[origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m)]!=0:#### Yes axes seem to be \"flipped\" !=0:\n",
    "            print ('reject point, most likely part of the audience, outside of the arena map')\n",
    "            \n",
    "    dists=(pose-np.asarray(xys))\n",
    "    human_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'human in {human_room}')\n",
    "    \n",
    "    robot_pose=get_robot_px()\n",
    "    dists=(robot_pose-np.asarray(xys))\n",
    "    robot_room=room_names[np.linalg.norm(dists, axis=1).argmin()]\n",
    "    print(f'Robot  in {robot_room}')\n",
    "    \n",
    "    if robot_room != human_room: print('maybe false positive... ignoring... ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ad20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_pose=get_robot_px()\n",
    "robot_pose_px=[origin_map_img[1]+ round(robot_pose[1]/pix_per_m),origin_map_img[0]+ round(robot_pose[0]/pix_per_m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0af51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose=get_robot_px()\n",
    "origin_map_img=[round(img_map.shape[0]*0.5) ,round(img_map.shape[1]*0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_map_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_robot_px()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "px_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a9e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53990f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iimg=draw_at(px_pose_robot[0] ,px_pose_robot[1], img_map )\n",
    "#iimg= draw_at(origin_map_img[1]+ round(pose[1]/pix_per_m),origin_map_img[0]+ round(pose[0]/pix_per_m), img_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(iimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97771c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px_pose_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_room= 'living_room'\n",
    "kl_pose_bedroom=(df[df['child_id_frame']=='bedroom'][['x','y','th']].values.ravel())\n",
    "kl_room=(df[df['child_id_frame']==next_room][['x','y','th']].values.ravel())\n",
    "kl_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_room=(df[df['child_id_frame']==next_room][['x','y','th']].values.ravel())\n",
    "omni_base.move_base(goal_x=kl_room[0],goal_y=kl_room[1],goal_theta=kl_room[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans, _=tf_man.getTF('base_link')\n",
    "robot_pose=np.asarray(trans[:2])\n",
    "    \n",
    "robot_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xys, room_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8782c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists=(robot_pose-np.asarray(xys))\n",
    "robot_room=room_names[np.linalg.norm(dists, axis=0).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11875734",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40998a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "drawing = False\n",
    "ix,iy = -1,-1\n",
    "\n",
    "# define mouse callback function to draw circle\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "   global ix, iy, drawing, img\n",
    "   if event == cv2.EVENT_LBUTTONDOWN:\n",
    "      drawing = True\n",
    "      ix = x\n",
    "      iy = y\n",
    "   elif event == cv2.EVENT_LBUTTONUP:\n",
    "      drawing = False\n",
    "      cv2.rectangle(img, (ix, iy),(x, y),(0, 255, 255),-1)\n",
    "\n",
    "# Create a black image\n",
    "img = np.zeros((512,700,3), np.uint8)\n",
    "\n",
    "# Create a window and bind the function to window\n",
    "cv2.namedWindow(\"Rectangle Window\")\n",
    "\n",
    "# Connect the mouse button to our callback function\n",
    "cv2.setMouseCallback(\"Rectangle Window\", draw_rectangle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85260252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mouse callback function to draw circle\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "   global ix, iy, drawing, img\n",
    "   if event == cv2.EVENT_LBUTTONDOWN:\n",
    "      drawing = True\n",
    "      ix = x\n",
    "      iy = y\n",
    "   elif event == cv2.EVENT_LBUTTONUP:\n",
    "      drawing = False\n",
    "      cv2.rectangle(img, (ix, iy),(x, y),(0, 255, 255),-1)\n",
    "\n",
    "# Create a black image\n",
    "img = np.zeros((512,700,3), np.uint8)\n",
    "\n",
    "# Create a window and bind the function to window\n",
    "cv2.namedWindow(\"Rectangle Window\")\n",
    "\n",
    "# Connect the mouse button to our callback function\n",
    "cv2.setMouseCallback(\"Rectangle Window\", draw_rectangle)\n",
    "\n",
    "# display the window\n",
    "while True:\n",
    "   cv2.imshow(\"Rectangle Window\", img)\n",
    "   if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4cc361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96022cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactive_markers.interactive_marker_server import *\n",
    "from visualization_msgs.msg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_marker = InteractiveMarker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c994bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveMarkerControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b10058",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = InteractiveMarkerControl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311dae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac24411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e7f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
